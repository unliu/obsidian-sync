# AI 时代的阅读和思考or注意力管理
https://www.xiaoyuzhoufm.com/episode/68a625c642cc2798e799448e

这段时间 Agentic AI 大热，大模型厂商卷得很凶猛，普通人使用  GPT 5 thinking、Gemini Pro 2.5 这样旗舰模型的成本正在极速下降。

随便一个什么问题，我们都可以扔给豆包或者一年免费的 Perplexity Pro 来做一个真正的「深入研究/Deep Research」，拿到一份结构清晰、详尽可靠的报告。甚至交给 Trae/Claude Code/CodeX 让它写出能配合人类登录、还能对抗反爬机制的爬虫，用 Comet 浏览器自动帮你注册网站拿到资料，再进行详细整理。一份看不懂的代码库，扔给免费的 Qoder 就可以生成数万字的项目 Wiki。（*）

几乎所有领域的所谓「专业性」门槛都在快速消失。互联网降低了知识的获取门槛，AI 降低的是知识的消化和吸收门槛。

### 二手知识和智能的本质

到今年，以 OpenAI 联合创始人 **Ilya Sutskever** 和马斯克为代表，所有从业者都意识到能用于模型训练的真实世界数据都已用尽或即将用尽，我们必须转向合成数据。

问题来了：二次合成的数据为什么能有意义？从小的教育告诉我们，即便人一生的阅读容量有限，也要尽量读原文、学习一手知识，而不应该学习二手知识。机器又何必学习二手知识？

这背后其实是 **Ilya** 的知名理论：智能的本质是压缩（原文：If you compress the data really well you must extract all the hidden secrets which exist in it. Therefore, that is the key）。



正是因为模型和人类一样，一次对话能运用的上下文是有限的，也就是：它的记忆和人类一样是有限的，因为就算它有无限的记忆，在一次对话中能用到的也极其有限。百万字节的上下文就已经算非常高，而且对首尾才能真的用好，中间段落即便放在上下文里也很难有效调用。

怎么办？压缩成参数记忆。把知识向量化为参数，能让一个五百多G 的 deepseek 来源模型回答世界上几乎所有领域的问题。

500G 还是太大怎么办？10G 的蒸馏版本也能回答上大部分。什么是蒸馏？其实就是用模型生成的内容训练模型。就像那么多物理系的本科生，都在读费曼的物理学讲义一样。

教科书的本质是压缩。智能的本质也是压缩。

如果把知识放在数据库里，这个数据库就需要无限大，每一次搜索都需要无限多的时间；但放在参数里，就可以做到立即响应，只有响应及时，才有真正的实用价值，才是真正的智能。

有了这个机制，机器就能「自己训练自己」，在有限的算力和存储空间里，无限地提升智能。

### 二手观点和人生导师

教科书是人类知识的压缩，本质上是现代知识是对「原始知识」的压缩。现代科学的碳水、蛋白质、维生素和矿物质理论压缩了神农尝百草的知识，使我们更加理解食物营养。万有引力压缩了日月之行，是我们不必成为天文专家也能理解天体运动。人类的「眼界」一代比一代更为宽阔。

那么，五分钟的「小美小帅」电影解说也是对电影的压缩，罗辑思维的一分钟看完一本书也是对书的压缩，为什么我们不觉得它们能提升人类智能呢？

03 年非典期间，三个小时的《一一》看了多遍，让我喜欢上了影像的世界，读了电影学的研究生，从知道杨德昌、安哲罗普洛斯，到知道罗兰巴特、哈贝马斯，打开了一扇新的窗。5分钟的解说绝不可能做到这一点。

就算平均一天拿出一小时看电影，人一辈子大概30000天，《一一》看一遍，就消耗掉了人一辈子万分之一的 quota。看十遍就是千分之一。

训练一个 AI，如果要把千分之一的算力和存储空间花在仅仅一部电影上，绝对不是一个划算的做法。毕竟人类历史上的电影总量是 100 万部。

人不必做一个「万能」的人。也不必做一个「有用」的人。

另一方面，无数的 AI 导师正在涌现。

碎片化的正确观点。

人类的参数记忆的差异，造成了人与人之间的差别。也会是模型与模型之间的差别。

通用的大模型是有用的。但每个人独特的参数记忆是有意志力和有趣的。

当你作为一个工具人或者 AI 助手存在时，你的意志力并不重要，趣味也并不重要。人类希望你有尽可能渊博的知识，但不希望你有太独特的「参数记忆」，因为这意味着你对世界进行了选择性的记忆。你的参数越多越好，万亿以上，最好千万亿。

获取尽可能优质的的二手知识，但建立自己独有的压缩和参数体系。

唯一解
《认知觉醒》里有一个说法

* 2025 年「AI 百日，恍若数年」的程度，可参考这篇文章：https://waytoagi.feishu.cn/wiki/OgACwnqWBiKo6okpYVycTTOBnDg
* 记忆开始卷起来了：https://www.36kr.com/p/3456206370838145
